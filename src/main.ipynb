{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6535, 4)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===================================== read datas =====================================\n",
    "user_id,content_type,timestamp,textual=[],[],[],[]\n",
    "with open('../data/Reputation_prediction_data_train.txt') as f:    \n",
    "    for line in f:\n",
    "        data = line.strip().split()\n",
    "        user_id.append(data[-3])\n",
    "        content_type.append(data[-2])\n",
    "        timestamp.append(data[-1])\n",
    "        textual.append(data[:-3])\n",
    "df_data = DataFrame({'user_id': user_id})\n",
    "df_data['user_id']=user_id\n",
    "df_data['content_type'] = content_type\n",
    "df_data['textual'] = textual\n",
    "#===================================== read labels =====================================\n",
    "user_id, label = [],[]\n",
    "with open('../data/Reputation_prediction_labels_train.txt') as f:    \n",
    "    for line in f:\n",
    "        data = line.strip().split()\n",
    "        user_id.append(data[0])\n",
    "        label.append(data[1])\n",
    "df_test = DataFrame()\n",
    "df_test['label']=label\n",
    "df_test['user_id'] = user_id\n",
    "#===================================== merge 2 dataframe =====================================\n",
    "df = pd.merge(df_data, df_test, on='user_id',how='left')\n",
    "#===================================== group data =====================================\n",
    "df_group = df.groupby(['user_id','content_type','label']).agg({'textual':'sum'}).add_suffix('_comb').reset_index()\n",
    "df_group['textual_comb']=[' '.join(i) for i in df_group.textual_comb]\n",
    "df_group.shape  #(6535, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>textual</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[basic, premis, restorationist, movement, ear,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[distinct, ordin, type, lds, church, recent, l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[origin, bridal, veil, christian, wed, practic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[accord, kingdom, theolog, man, hold, secular,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[differ, elder, led, elder, rule, church, gove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[distinct, exhibit, true, furqan, book, true, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>13</td>\n",
       "      <td>Q</td>\n",
       "      <td>[matthew, mark, luke, call, synopt, gospel, go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>14</td>\n",
       "      <td>Q</td>\n",
       "      <td>[fast, daniel, cyrus, king, persia, reveal, da...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>14</td>\n",
       "      <td>Q</td>\n",
       "      <td>[pray, bold, pray, person, achiev, pray, selfl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>15</td>\n",
       "      <td>Q</td>\n",
       "      <td>[differ, judg, god, question, god, answer, man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id content_type                                            textual  \\\n",
       "190      13            Q  [basic, premis, restorationist, movement, ear,...   \n",
       "191      13            Q  [distinct, ordin, type, lds, church, recent, l...   \n",
       "192      13            Q  [origin, bridal, veil, christian, wed, practic...   \n",
       "193      13            Q  [accord, kingdom, theolog, man, hold, secular,...   \n",
       "194      13            Q  [differ, elder, led, elder, rule, church, gove...   \n",
       "195      13            Q  [distinct, exhibit, true, furqan, book, true, ...   \n",
       "196      13            Q  [matthew, mark, luke, call, synopt, gospel, go...   \n",
       "197      14            Q  [fast, daniel, cyrus, king, persia, reveal, da...   \n",
       "198      14            Q  [pray, bold, pray, person, achiev, pray, selfl...   \n",
       "199      15            Q  [differ, judg, god, question, god, answer, man...   \n",
       "\n",
       "    label  \n",
       "190     1  \n",
       "191     1  \n",
       "192     1  \n",
       "193     1  \n",
       "194     1  \n",
       "195     1  \n",
       "196     1  \n",
       "197     3  \n",
       "198     3  \n",
       "199     1  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[190:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df = df_group[df_group['content_type']=='A']\n",
    "C_df = df_group[df_group['content_type']=='C']\n",
    "E_df = df_group[df_group['content_type']=='E']\n",
    "F_df = df_group[df_group['content_type']=='F']\n",
    "Q_df = df_group[df_group['content_type']=='Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_group = F_df\n",
    "a_train, a_test, b_train, b_test = train_test_split(df_group.textual_comb,df_group.label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_group['textual'].to_frame()\n",
    "# agg_df.index=agg_df.index.map(int)\n",
    "# agg_df.sort_index(inplace=True)\n",
    "# agg_df['label']= df_test['label'].tolist()\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X)\n",
    "# X_train_tf = tf_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6223241590214067"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,6))),\n",
    "                     ('clf', MultinomialNB())])\n",
    "text_clf.fit(a_train, b_train)  \n",
    "predicted = text_clf.predict(a_test)\n",
    "np.mean(predicted == b_test)   \n",
    "# avg = 0.58730158730158732,\n",
    "# 1=0.50917431192660545, ->0.54 0.001\n",
    "# 2=0.55045871559633031, ->0.628 0.001\n",
    "# 3=0.58715596330275233, ->0.633 0.001\n",
    "# 4=0.6009174311926605, -> 0.628 0.001\n",
    "# 5=0.610(alpha = 1e-2 0.6239)(1e-1 0.617)\n",
    "# 6=0.6223241590214067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65749235474006118"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,4))),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=20,max_iter=5, tol=None)),])\n",
    "text_clf.fit(a_train, b_train)  \n",
    "predicted = text_clf.predict(a_test)\n",
    "np.mean(predicted == b_test)  \n",
    "# 0.65749235474006118  ngram_range=(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "# #               'vet__lowercase':(True,False),\n",
    "#               'clf__alpha': (1e-2, 1e-3),\n",
    "# }\n",
    "# gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(df_group.textual_comb,df_group.label)\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/26569478/performing-grid-search-on-sklearn-naive-bayes-multinomialnb-on-multi-core-machin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_group.label\n",
    "X = df_group.textual_comb\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "unigram_log_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('logreg', linear_model.LogisticRegression())\n",
    "])\n",
    "\n",
    "ngram_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "tfidf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(use_idf = False\n",
    "                              )),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "classifiers = [\n",
    "#     (\"ngram\", ngram_pipe),\n",
    "    (\"unigram\", unigram_log_pipe),\n",
    "    (\"tfidf\", tfidf_pipe),\n",
    "]\n",
    "\n",
    "mixed_pipe = Pipeline([\n",
    "    (\"voting\", VotingClassifier(classifiers, voting=\"soft\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] voting__weights=[0, 1] ..........................................\n",
      "[CV] voting__weights=[0, 1] ..........................................\n",
      "[CV] voting__weights=[0, 1] ..........................................\n",
      "[CV] voting__weights=[1, 0] ..........................................\n",
      "[CV]  voting__weights=[0, 1], score=-1.6297249128372548, total=   5.3s\n",
      "[CV] voting__weights=[1, 0] ..........................................\n",
      "[CV]  voting__weights=[0, 1], score=-1.3037999134087996, total=   5.4s\n",
      "[CV] voting__weights=[1, 0] ..........................................\n",
      "[CV]  voting__weights=[0, 1], score=-1.4404642106298107, total=   6.1s\n",
      "[CV] voting__weights=[1, 1] ..........................................\n",
      "[CV] . voting__weights=[1, 0], score=-2.321808167499604, total=   5.9s\n",
      "[CV] voting__weights=[1, 1] ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    7.2s remaining:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    7.4s remaining:    9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . voting__weights=[1, 0], score=-2.412997038792653, total=   1.2s\n",
      "[CV] voting__weights=[1, 1] ..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed:    8.2s remaining:    6.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . voting__weights=[1, 0], score=-2.107421822351222, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.7s remaining:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . voting__weights=[1, 1], score=-1.484673384288052, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    9.4s remaining:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  voting__weights=[1, 1], score=-1.2740355793169027, total=   1.5s\n",
      "[CV] . voting__weights=[1, 1], score=-1.248309040277653, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'voting__weights': [0, 1]} -1.45799634563\n",
      "{'voting__weights': [1, 0]} -2.28074234288\n",
      "{'voting__weights': [1, 1]} -1.33567266796\n",
      "Best score: -1.336\n",
      "Best parameters set:\n",
      "\tvoting__weights: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "def combinations_on_off(num_classifiers):\n",
    "    return [[int(x) for x in list(\"{0:0b}\".format(i).zfill(num_classifiers))]\n",
    "            for i in range(1, 2 ** num_classifiers)]\n",
    "\n",
    "param_grid = dict(\n",
    "    voting__weights=combinations_on_off(len(classifiers))\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(mixed_pipe, param_grid=param_grid, n_jobs=-1, verbose=10, scoring=\"neg_log_loss\")\n",
    "\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(params, mean_score)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([('vec', CountVectorizer(encoding='cp874',  token_pattern=None)),\n",
    "#                      ('tfidf', TfidfTransformer()), \n",
    "#                      ('clf',MultinomialNB())])\n",
    "# parameters = {  \n",
    "# 'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0),  \n",
    "# 'vec__max_features': (None, 5000, 10000, 20000),  \n",
    "# 'vec__min_df': (1, 5, 10, 20, 50),  \n",
    "# 'tfidf__use_idf': (True, False),  \n",
    "# 'tfidf__sublinear_tf': (True, False),  \n",
    "# 'vec__binary': (True, False),  \n",
    "# 'tfidf__norm': ('l1', 'l2'),  \n",
    "# 'clf__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)  \n",
    "# }  \n",
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2)  \n",
    "# grid_search.fit(df_group.textual_comb,df_group.label)  \n",
    "# print(\"Best score: {0}\".format(grid_search.best_score_))  \n",
    "# print(\"Best parameters set:\")  \n",
    "# best_parameters = grid_search.best_estimator_.get_params()  \n",
    "# for param_name in sorted(list(parameters.keys())):  \n",
    "#     print(\"\\t{0}: {1}\".format(param_name, best_parameters[param_name]))\n",
    "# https://stackoverflow.com/questions/26569478/performing-grid-search-on-sklearn-naive-bayes-multinomialnb-on-multi-core-machin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
